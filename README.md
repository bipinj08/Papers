# Unmanned Aerial Vehicle Path Planning Optimization

This repository contains code and resource links and an original paper titled "Unmanned Aerial Vehicle Path Planning Optimization: A Comparative Study of DDQN, PPO, and MuZero Algorithms".

## Overview

In this paper, we explore the effectiveness of three different reinforcement learning algorithms, namely Double Deep Q-Network (DDQN), Proximal Policy Optimization (PPO), and MuZero, for optimizing path planning of Unmanned Aerial Vehicles (UAVs). We provide implementations of these algorithms along with necessary resources and documentation to facilitate understanding and replication of our experiments.

## Repository Structure

- `code/`: Contains the implementation of the PPO algorithm. ([Link to Code](https://github.com/bipinj08/Coverage-Path-Planning-Using-PPO.git)).
- `code/`: Contains the implementation of the PPO algorithm. ([Link to Code](https://github.com/bipinj08/Coverage-Path-Planning-Using-MuZero.git).
- `README.md`: This file provides an overview of the repository.

## Getting Started

To get started with using the code and replicating our experiments, please refer to the following steps:

1. Clone this repository to your local machine and the repository for the code from the respective repository.

